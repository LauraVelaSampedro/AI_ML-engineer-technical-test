{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_AI infrastructure and ML engineer technical test_LauraVelaSampedro.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oNGZugHLuaB6",
        "kqKPCxXAunJh",
        "zpK5qKyCplM4",
        "RFvdgqtjkTv7",
        "p93ClkIIvgpl",
        "tv8cKHitpGWY",
        "b9KaXQay-mTf"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b8eb22f3770c4a0691b5f96fd6864432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fc4eae3460334d97950433353c3f947b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_62a410cfdff64d8dadfa7b31d809c20b",
              "IPY_MODEL_482759b81d474fd7931f835765687011",
              "IPY_MODEL_2236d407e2ca49fe8ec56e24382781b3"
            ]
          }
        },
        "fc4eae3460334d97950433353c3f947b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62a410cfdff64d8dadfa7b31d809c20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d36ae2477cd84bd1a159d00f726834c9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c209f20c841c4208884df262a95fd6af"
          }
        },
        "482759b81d474fd7931f835765687011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_af80454549b041c399ee269e0e57798f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16e2caf4b56a489db91c64388ae2cde0"
          }
        },
        "2236d407e2ca49fe8ec56e24382781b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d5ee6c3da25043a9bb6422cdad42a19f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 351kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a4d1a97593e4cce86597fdf4160ac98"
          }
        },
        "d36ae2477cd84bd1a159d00f726834c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c209f20c841c4208884df262a95fd6af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af80454549b041c399ee269e0e57798f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16e2caf4b56a489db91c64388ae2cde0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5ee6c3da25043a9bb6422cdad42a19f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a4d1a97593e4cce86597fdf4160ac98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa9c1271d2a84c3491400c91b617e589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5aec79d192274f9489900474864ea30d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fe6e4b6b5d4a4c5fb94d27c8bef022d6",
              "IPY_MODEL_039905b077b74e1090741b4fc94c3f4f",
              "IPY_MODEL_51f6e633f935406686d2bb5185e582f7"
            ]
          }
        },
        "5aec79d192274f9489900474864ea30d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe6e4b6b5d4a4c5fb94d27c8bef022d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7ce55d27d178471f9b40ae7e027209b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46487557663e45f5b7e2edf7c1223840"
          }
        },
        "039905b077b74e1090741b4fc94c3f4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5e6c94fac2404bbab6e1e23a444b78b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1f8ba8587c74e96940afaa43ad9a29c"
          }
        },
        "51f6e633f935406686d2bb5185e582f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0b204b4ca96d4dbc95fc4d06fde9e78f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 710B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_922737e171a74092a0cd870e602c8dda"
          }
        },
        "7ce55d27d178471f9b40ae7e027209b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46487557663e45f5b7e2edf7c1223840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e6c94fac2404bbab6e1e23a444b78b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1f8ba8587c74e96940afaa43ad9a29c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b204b4ca96d4dbc95fc4d06fde9e78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "922737e171a74092a0cd870e602c8dda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6e2100761294054b23dda4600eb1a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_911f5efec12644d38732228c5df58e4f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_247db455a1374c9ca3543bb756855ac7",
              "IPY_MODEL_956e5ab472bf43aa914f646668570f5a",
              "IPY_MODEL_6b76e2cfca1f422d95ac5dff66f03315"
            ]
          }
        },
        "911f5efec12644d38732228c5df58e4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "247db455a1374c9ca3543bb756855ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4bfc2ff8443c4545b9a91d606b9d128f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e1df319a9194304a53ab07e990b42b4"
          }
        },
        "956e5ab472bf43aa914f646668570f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_94055c04e77a4bc5a519e6ac11f579f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5dcc6f2732384bda9ea28f0953398bfe"
          }
        },
        "6b76e2cfca1f422d95ac5dff66f03315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_31a4af39b566425794d5c75064c2cc2d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 653kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_232d565b81f040ffacef2519a7d7afda"
          }
        },
        "4bfc2ff8443c4545b9a91d606b9d128f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e1df319a9194304a53ab07e990b42b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94055c04e77a4bc5a519e6ac11f579f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5dcc6f2732384bda9ea28f0953398bfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31a4af39b566425794d5c75064c2cc2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "232d565b81f040ffacef2519a7d7afda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5754d21a0207482b93b3c99064638cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_16d1df343dc94e7089f945aeeed90115",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fc226e7be01e402f81aeb41be6baf421",
              "IPY_MODEL_31f51d7e2734449ebb46e7c39285e518",
              "IPY_MODEL_aa5ecfdb57db4948af59cc06a5e35e21"
            ]
          }
        },
        "16d1df343dc94e7089f945aeeed90115": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc226e7be01e402f81aeb41be6baf421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_242b1ab423e3430cbf8f8cc0bcbc49c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a3e83d8973d474194d3cca1fe2530ab"
          }
        },
        "31f51d7e2734449ebb46e7c39285e518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_92974d6b3ea24cc5a7c4c096ad3790f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55de683f6ae34d369cb4cead6bf36997"
          }
        },
        "aa5ecfdb57db4948af59cc06a5e35e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4ba28bb6ab7847429eac74344191830a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 13.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ffd87f7ffb3c46b2b1f56aae8f1c0976"
          }
        },
        "242b1ab423e3430cbf8f8cc0bcbc49c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a3e83d8973d474194d3cca1fe2530ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92974d6b3ea24cc5a7c4c096ad3790f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55de683f6ae34d369cb4cead6bf36997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ba28bb6ab7847429eac74344191830a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ffd87f7ffb3c46b2b1f56aae8f1c0976": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LauraVelaSampedro/AI_ML-engineer-technical-test/blob/main/Final_AI_infrastructure_and_ML_engineer_technical_test_LauraVelaSampedro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNGZugHLuaB6"
      },
      "source": [
        "## 0. Packages intallation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcdR62R3NrlZ",
        "outputId": "ff27e0be-455c-4c6b-ef01-2249e0f8377c"
      },
      "source": [
        "!pip install langdetect\n",
        "!pip install transformers\n",
        "!pip install sentence-transformers\n",
        "!pip install ktrain\n",
        "!pip install scikit-plot\n",
        "!pip install pytorch-pretrained-bert pytorch-nlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 71 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 81 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 92 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 102 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 112 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 122 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 133 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 143 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 153 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 163 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 174 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 184 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 194 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 204 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 215 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 225 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 235 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 245 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 256 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 266 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 286 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 296 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 317 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 327 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 348 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 358 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 378 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 389 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 409 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 419 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 440 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 450 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 471 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 481 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 501 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 512 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 532 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 542 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 563 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 573 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 593 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 604 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 624 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 634 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 655 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 665 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 686 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 696 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 716 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 727 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 747 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 757 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 768 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 778 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 788 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 798 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 808 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 819 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 829 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 839 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 849 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 860 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 870 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 880 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 890 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 901 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 911 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 921 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 931 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 942 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 952 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 962 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 972 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 981 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=7a680a5314f5ee6802ac2c85fc9030fadad0f720157310bcf64fc486c013257a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.12.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 4.1 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 54.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 37.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.2\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.1.0.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: tokenizers>=0.10.3 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 25.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.0.19)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.46)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-py3-none-any.whl size=121000 sha256=27caac48c1163afb73c09c26c1c561eebe7c16e49c5d8a4676bff14e73de10c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/f0/bb/ed1add84da70092ea526466eadc2bfb197c4bcb8d4fa5f7bad\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.1.0 sentencepiece-0.1.96\n",
            "Collecting ktrain\n",
            "  Downloading ktrain-0.28.2.tar.gz (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 65 kB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 30.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.2.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.1.5)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ktrain) (21.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.9)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.42.1)\n",
            "Collecting cchardet\n",
            "  Downloading cchardet-2.1.7-cp37-cp37m-manylinux2010_x86_64.whl (263 kB)\n",
            "\u001b[K     |████████████████████████████████| 263 kB 49.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.0.4)\n",
            "Collecting syntok\n",
            "  Downloading syntok-1.3.1.tar.gz (23 kB)\n",
            "Collecting seqeval==0.0.19\n",
            "  Downloading seqeval-0.0.19.tar.gz (30 kB)\n",
            "Collecting transformers<=4.10.3,>=4.0.0\n",
            "  Downloading transformers-4.10.3-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 29.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.1.96)\n",
            "Collecting keras_bert>=0.86.0\n",
            "  Downloading keras-bert-0.88.0.tar.gz (26 kB)\n",
            "Collecting whoosh\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[K     |████████████████████████████████| 468 kB 37.1 MB/s \n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.4.1)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.19->ktrain) (2.6.0)\n",
            "Collecting keras-transformer>=0.39.0\n",
            "  Downloading keras-transformer-0.39.0.tar.gz (11 kB)\n",
            "Collecting keras-pos-embd>=0.12.0\n",
            "  Downloading keras-pos-embd-0.12.0.tar.gz (6.0 kB)\n",
            "Collecting keras-multi-head>=0.28.0\n",
            "  Downloading keras-multi-head-0.28.0.tar.gz (14 kB)\n",
            "Collecting keras-layer-normalization>=0.15.0\n",
            "  Downloading keras-layer-normalization-0.15.0.tar.gz (4.2 kB)\n",
            "Collecting keras-position-wise-feed-forward>=0.7.0\n",
            "  Downloading keras-position-wise-feed-forward-0.7.0.tar.gz (4.5 kB)\n",
            "Collecting keras-embed-sim>=0.9.0\n",
            "  Downloading keras-embed-sim-0.9.0.tar.gz (4.1 kB)\n",
            "Collecting keras-self-attention>=0.50.0\n",
            "  Downloading keras-self-attention-0.50.0.tar.gz (12 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0.0->ktrain) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (3.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (4.62.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (0.0.46)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (4.8.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (0.0.19)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (0.10.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers<=4.10.3,>=4.0.0->ktrain) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.10.3,>=4.0.0->ktrain) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.10.3,>=4.0.0->ktrain) (7.1.2)\n",
            "Building wheels for collected packages: ktrain, seqeval, keras-bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, syntok\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.28.2-py3-none-any.whl size=25290606 sha256=466c12fb8d0626153d84b6ca7677973c5404ad3d10263c3f8fad5ba7c3fbbf80\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/2b/04/7c821b51e637ec480060989b5030d0c4cce16efe0d67bff94b\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.19-py3-none-any.whl size=9929 sha256=e4983b897ff4f523be7a3894065d8900c14ded987227327827711641cb4b830f\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/ac/f1/4e13d7aff05c722d142b7d20a88ad63f9aab11b895411241a4\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.88.0-py3-none-any.whl size=34204 sha256=da2aa8b264ca8de01a149da819881df2a1745aa741b858318ef6c35b5885eccc\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/90/cd/c038f2366929a3a5e3414a303b673e10235e802d871d29a835\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.39.0-py3-none-any.whl size=12842 sha256=94f7653df2b549d0842e6085f1cc76b343860809ece2b417f612b5fe85c85b62\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/01/e0/5a1a14bed6726f2ed73f7917d2d2c2d4081d2c88426dea07ce\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.9.0-py3-none-any.whl size=4504 sha256=ccb59085e605be217fc76966fa859434a490d21c483f47afb2ba82e33ee0304e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/1e/d2/9bc15513dd2f8b9de3e628b3aa9d2de49e721deef6bbd1497e\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.15.0-py3-none-any.whl size=5224 sha256=8cd7818041d9b9a4a66d426f8a802cb7dad024107f7a995c82466dedbac855d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/be/fe/55422f77ac11fe6ddcb471198038de8a26b5a4dd1557883c1e\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.28.0-py3-none-any.whl size=15559 sha256=e4d5cf26c31383d38ef3ea30f8031c8e78c8fe0945b3afeab228b4017a16a56f\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/4a/ea/9503ab5a02201dfb8635ba2cc8f30844661623c684a5b44472\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.12.0-py3-none-any.whl size=7469 sha256=3886b3200529a29c12e46619704c617179a741a8e213be4378a9971f1594c3d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/99/fd/dd98f4876c3ebbef7aab0dbfbd37bca41d7db37d3a28b2cb09\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.7.0-py3-none-any.whl size=5541 sha256=8504ae1f5d8091a974cba360057cf591bc7432e68c8a93ebd965defb53874240\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/12/02/1ad455c4f181cda1a4e60c5445855853d5c2ea91f942586a04\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.50.0-py3-none-any.whl size=19414 sha256=b0668bebf8f578e420f43112549569cda75adf07bc127c9f97a3a4c9be25601e\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/7a/a3/231bef5803298e7ec1815215bc0613239cb1e9c03c57b13c14\n",
            "  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for syntok: filename=syntok-1.3.1-py3-none-any.whl size=20917 sha256=acd0a59c618267507a477d2fcdb31b3a586dc3cfc8da5eb2748d1f0cf6bd9b42\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/c2/33/e5d7d8f2f8b0c391d76bf82b844c3151bf23a84d75d02b185f\n",
            "Successfully built ktrain seqeval keras-bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention syntok\n",
            "Installing collected packages: keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-embed-sim, threadpoolctl, keras-transformer, whoosh, transformers, syntok, seqeval, scikit-learn, keras-bert, cchardet, ktrain\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.12.2\n",
            "    Uninstalling transformers-4.12.2:\n",
            "      Successfully uninstalled transformers-4.12.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed cchardet-2.1.7 keras-bert-0.88.0 keras-embed-sim-0.9.0 keras-layer-normalization-0.15.0 keras-multi-head-0.28.0 keras-pos-embd-0.12.0 keras-position-wise-feed-forward-0.7.0 keras-self-attention-0.50.0 keras-transformer-0.39.0 ktrain-0.28.2 scikit-learn-0.23.2 seqeval-0.0.19 syntok-1.3.1 threadpoolctl-3.0.0 transformers-4.10.3 whoosh-2.7.4\n",
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (0.23.2)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.0.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n",
            "Collecting pytorch-pretrained-bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting pytorch-nlp\n",
            "  Downloading pytorch_nlp-0.5.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.9.0+cu111)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.19.7-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 41.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting botocore<1.23.0,>=1.22.7\n",
            "  Downloading botocore-1.22.7-py3-none-any.whl (8.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.1 MB 37.1 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 47.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.23.0,>=1.22.7->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.23.0,>=1.22.7->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 49.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, pytorch-nlp\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.19.7 botocore-1.22.7 jmespath-0.10.0 pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.5.0 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syCXFpyXQ0kM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bbb76c5-4766-4a6d-94ed-deba20c5ad70"
      },
      "source": [
        "# Connection with Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIQlFVHXQ66d"
      },
      "source": [
        "# Definition of the project base folder\n",
        "dir_base = \"/content/drive/My Drive/Sorcero_Test\"\n",
        "dir_dataset = dir_base + \"/data/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd80LF4lNBL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc4e7ae9-dd36-4fe8-f4a9-f2fc0f4104d5"
      },
      "source": [
        "# Importing useful libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "%matplotlib inline\n",
        "%time\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import sys\n",
        "import string\n",
        "import regex\n",
        "from tqdm.notebook import tqdm\n",
        "from tqdm import tqdm, trange\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from langdetect import detect, DetectorFactory\n",
        "from transformers import TFBertModel, create_optimizer, BertTokenizer, BertModel\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from ktrain import text\n",
        "import scikitplot as skplt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 4.77 µs\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBzezfmmx988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "abc45680-22dc-49eb-a7c9-765ab1d58539"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqKPCxXAunJh"
      },
      "source": [
        "## 1. Exploring the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huAncjdjaVIA"
      },
      "source": [
        "# Importing dataset\n",
        "\n",
        "df_dev = pd.read_csv(dir_dataset + \"/dev.tsv\",sep= \"\\t\", index_col=0)\n",
        "df_train = pd.read_csv(dir_dataset + \"/train.tsv\",sep= \"\\t\", index_col=0)\n",
        "df_test = pd.read_csv(dir_dataset + \"/test.tsv\", sep= \"\\t\", index_col=0)\n",
        "\n",
        "df_dataset = pd.concat([df_dev, df_train, df_test]) # Concatenating datasets for easy preprocessing"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URq5kpq7cyuV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "7821a0ff-ec0e-4ff4-d17d-e7b4c3c8ef3f"
      },
      "source": [
        "# Exploring dataset\n",
        "df_dataset.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim</th>\n",
              "      <th>date_published</th>\n",
              "      <th>explanation</th>\n",
              "      <th>fact_checkers</th>\n",
              "      <th>main_text</th>\n",
              "      <th>sources</th>\n",
              "      <th>label</th>\n",
              "      <th>subjects</th>\n",
              "      <th>claim_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34656</th>\n",
              "      <td>A baby died at an unnamed medical facility be...</td>\n",
              "      <td>November 10, 2015</td>\n",
              "      <td>Fellow Twitter users suggested @FierceFemtivis...</td>\n",
              "      <td>Kim LaCapria</td>\n",
              "      <td>On 8 November 2015, former Twitter user @Fierc...</td>\n",
              "      <td>http://webcache.googleusercontent.com/search?q...</td>\n",
              "      <td>unproven</td>\n",
              "      <td>Politics, fiercefemtivist, racism</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3632</th>\n",
              "      <td>Bat from Shawnee County tests positive for rab...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A bat found in northeastern Kansas has tested ...</td>\n",
              "      <td></td>\n",
              "      <td>Topeka television station KSNT reports that th...</td>\n",
              "      <td>https://www.ksnt.com/news/bat-tests-positive-f...</td>\n",
              "      <td>true</td>\n",
              "      <td>Rabies, Health, General News, Kansas, Bats, To...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29558</th>\n",
              "      <td>Germany has banned pork from school canteens b...</td>\n",
              "      <td>March 7, 2016</td>\n",
              "      <td>What's true: Some politicians complained that ...</td>\n",
              "      <td>Kim LaCapria</td>\n",
              "      <td>On 7 March 2016, British tabloid Express repor...</td>\n",
              "      <td>http://bnp.org.uk/news/regional/bnp-victory-br...</td>\n",
              "      <td>false</td>\n",
              "      <td>Politics</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8416</th>\n",
              "      <td>Coronavirus prompts Canada to roll out safe dr...</td>\n",
              "      <td>April 16, 2020</td>\n",
              "      <td>Canada’s Pacific province of British Columbia ...</td>\n",
              "      <td>Tessa Vikander</td>\n",
              "      <td>In March, the Canadian government urged provin...</td>\n",
              "      <td></td>\n",
              "      <td>true</td>\n",
              "      <td>Health News</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7169</th>\n",
              "      <td>Wayne National Forest plans fires for tree, wi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Nearly 2,000 acres of Wayne National Forest in...</td>\n",
              "      <td></td>\n",
              "      <td>Forest officials say scientists who study nati...</td>\n",
              "      <td></td>\n",
              "      <td>true</td>\n",
              "      <td>Plants, Wildlife, Health, Wildlife health, For...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   claim  ... claim_id\n",
              "34656   A baby died at an unnamed medical facility be...  ...      NaN\n",
              "3632   Bat from Shawnee County tests positive for rab...  ...      NaN\n",
              "29558  Germany has banned pork from school canteens b...  ...      NaN\n",
              "8416   Coronavirus prompts Canada to roll out safe dr...  ...      NaN\n",
              "7169   Wayne National Forest plans fires for tree, wi...  ...      NaN\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmfEGBDCeejk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f04c5af0-6403-4681-d7a4-beb0d67e3d50"
      },
      "source": [
        "df_dataset[\"label\"].unique() # Noise is detected in the label column (labels different from the expected 4 described in https://huggingface.co/datasets/health_fact)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['unproven', 'true', 'false', 'mixture', nan,\n",
              "       'National, Candidate Biography, Donald Trump, ', 'snopes'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpK5qKyCplM4"
      },
      "source": [
        "## 2. Cleaning the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bv4hLBxnDlr"
      },
      "source": [
        "# Dropping noise rows (label different from the expected 4)\n",
        "\n",
        "df_dataset = df_dataset.loc[(df_dataset['label'] == 'unproven') | (df_dataset['label'] == 'true') | (df_dataset['label'] == 'false') | (df_dataset['label'] == 'mixture')]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtaILVDLpbSp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "a9931ee9-c1e3-43b2-bac8-528d207b368a"
      },
      "source": [
        "display(df_dataset.groupby(by='label').size()) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "label\n",
              "false       3769\n",
              "mixture     1799\n",
              "true        6306\n",
              "unproven     377\n",
              "dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cWqiX_2ppDV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "1f9e4091-2173-4a93-ee07-677cfc8270fa"
      },
      "source": [
        "df_dataset['label'].hist()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efd519db710>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gebtnKTgpxJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea23bd7-1452-4fc4-c41d-d137b4e65cca"
      },
      "source": [
        "df_dataset.isna().sum() # Checking that claim column does not have nan values"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "claim                 0\n",
              "date_published     2398\n",
              "explanation           0\n",
              "fact_checkers         0\n",
              "main_text             0\n",
              "sources               1\n",
              "label                 0\n",
              "subjects              0\n",
              "claim_id          11018\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYqCMa-gpdzr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2066813b-5724-4fd7-9dc5-27977f2e7ac2"
      },
      "source": [
        "df_dataset.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12251, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCkweAKSnyOu"
      },
      "source": [
        "# Converting label column to numerical\n",
        "#### true - 0\n",
        "#### false - 1\n",
        "#### mixture - 2\n",
        "#### unproven - 3\n",
        "#df_dataset['label_desc'] = df_dataset['label'] \n",
        "df_dataset['label'].replace(to_replace=['true', 'false', 'mixture', 'unproven'], value=[0, 1, 2, 3], inplace=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyoeQ4JvshA-"
      },
      "source": [
        "# Language review to ensure that the claims are written in English ############\n",
        "df_dataset['Language'] = df_dataset['claim'].apply(detect)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSu0oDMtXA4M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "4f0a14cd-0c2b-44fa-8358-a20278b601b4"
      },
      "source": [
        "display(df_dataset.groupby(by='Language').size()) # Claims in other languages different to English (English is the expected language according to https://huggingface.co/datasets/health_fact))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Language\n",
              "af       18\n",
              "ca       20\n",
              "cy        1\n",
              "da       16\n",
              "de       25\n",
              "en    12091\n",
              "es        5\n",
              "et        2\n",
              "fr       23\n",
              "hr        1\n",
              "id        2\n",
              "it       13\n",
              "lt        1\n",
              "nl       14\n",
              "no        4\n",
              "ro        6\n",
              "sv        1\n",
              "tl        6\n",
              "tr        1\n",
              "vi        1\n",
              "dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAFp07IzsLMU"
      },
      "source": [
        "idx_drop = df_dataset[(df_dataset['Language'] != \"en\")].index # Removing all claims in other language\n",
        "df_dataset.drop(idx_drop, inplace = True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fio7pYedjKIa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c32f9b27-388a-4eea-fe48-1ba5c74dd0f2"
      },
      "source": [
        "df_dataset.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12091, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnMWNE_bTcNm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1909a51a-dc8c-4960-e97b-717324550637"
      },
      "source": [
        "df_dataset.columns"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['claim', 'date_published', 'explanation', 'fact_checkers', 'main_text',\n",
              "       'sources', 'label', 'subjects', 'claim_id', 'Language'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx4DFV5WvyDa"
      },
      "source": [
        "# Keeping important columns\n",
        "df_dataset = df_dataset.loc[:, ['claim', 'label']]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR6YxqbdS6XX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d05ca6ca-0571-41d3-8a5a-089a54b2d5dd"
      },
      "source": [
        "df_dataset.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34656</th>\n",
              "      <td>A baby died at an unnamed medical facility be...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3632</th>\n",
              "      <td>Bat from Shawnee County tests positive for rab...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29558</th>\n",
              "      <td>Germany has banned pork from school canteens b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8416</th>\n",
              "      <td>Coronavirus prompts Canada to roll out safe dr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7169</th>\n",
              "      <td>Wayne National Forest plans fires for tree, wi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   claim  label\n",
              "34656   A baby died at an unnamed medical facility be...      3\n",
              "3632   Bat from Shawnee County tests positive for rab...      0\n",
              "29558  Germany has banned pork from school canteens b...      1\n",
              "8416   Coronavirus prompts Canada to roll out safe dr...      0\n",
              "7169   Wayne National Forest plans fires for tree, wi...      0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceuEHSoiqPmW"
      },
      "source": [
        "# Saving the cleaned dataset from dataframe to csv\n",
        "\n",
        "df_dataset.to_csv(dir_dataset + \"claims_dataset_cleaned.csv\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUszB9DTefxN"
      },
      "source": [
        "## _______________________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZZRfw0p8CDG"
      },
      "source": [
        "*Points 1 and 2 can be skipped and jumping directly from 0 to 3. Connecting with cleaned dataset*\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFvdgqtjkTv7"
      },
      "source": [
        "## 3. Connecting with the cleaned dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHDpDiLI8T7D"
      },
      "source": [
        "# Reading csv dataset cleaned in steps 1 and 2\n",
        "\n",
        "df_dataset = pd.read_csv(dir_dataset + \"claims_dataset_cleaned.csv\", index_col=0)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTPsBLJIxFEX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "9e09b901-a9e5-402a-9af8-58c786360647"
      },
      "source": [
        "display(df_dataset)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34656</th>\n",
              "      <td>A baby died at an unnamed medical facility be...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3632</th>\n",
              "      <td>Bat from Shawnee County tests positive for rab...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29558</th>\n",
              "      <td>Germany has banned pork from school canteens b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8416</th>\n",
              "      <td>Coronavirus prompts Canada to roll out safe dr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7169</th>\n",
              "      <td>Wayne National Forest plans fires for tree, wi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>Christmas miracle for Florida dog whose heart ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1231</th>\n",
              "      <td>Another dolphin dies at Arizona aquatic facility.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1232</th>\n",
              "      <td>What the facts say\" is ... \"the best scenario ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1233</th>\n",
              "      <td>FDA advisory panel rejects J&amp;J drug for acute ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1234</th>\n",
              "      <td>Gene-editing Chinese scientist kept much of hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12091 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   claim  label\n",
              "34656   A baby died at an unnamed medical facility be...      3\n",
              "3632   Bat from Shawnee County tests positive for rab...      0\n",
              "29558  Germany has banned pork from school canteens b...      1\n",
              "8416   Coronavirus prompts Canada to roll out safe dr...      0\n",
              "7169   Wayne National Forest plans fires for tree, wi...      0\n",
              "...                                                  ...    ...\n",
              "1230   Christmas miracle for Florida dog whose heart ...      0\n",
              "1231   Another dolphin dies at Arizona aquatic facility.      0\n",
              "1232   What the facts say\" is ... \"the best scenario ...      1\n",
              "1233   FDA advisory panel rejects J&J drug for acute ...      0\n",
              "1234   Gene-editing Chinese scientist kept much of hi...      0\n",
              "\n",
              "[12091 rows x 2 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JnBQFRU4-gE"
      },
      "source": [
        "# Once we have preprocessed the dataset, we split it again in train and test subsets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_dataset.claim.values\n",
        "y = df_dataset.label.values\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=7) # Split between train and validation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.25, random_state=7) #Split between train and test"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p93ClkIIvgpl"
      },
      "source": [
        "## 4. Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pjlCGpkpAij"
      },
      "source": [
        "### Claim standarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBvGpO7ioEAn"
      },
      "source": [
        "In order to process and classify claims, we need to bring the text into a form that is predictable and analyzable. To do so, we apply the function *claim_processing*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUq36fBMbqul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb0305ba-b15b-4684-f2b0-3bb8e7bcc6c4"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "def claim_preprocessing(claim):\n",
        "    # Lowercasing the sentence\n",
        "    claim = claim.lower() \n",
        "    # Changing 't to 'not'\n",
        "    claim = re.sub(r\"\\'t\", \" not\", claim) \n",
        "    # Removing @name\n",
        "    claim = re.sub(r'(@.*?)[\\s]', ' ', claim)\n",
        "    # Removing punctuations except '?'\n",
        "    claim = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', claim)\n",
        "    claim = re.sub(r'[^\\w\\s\\?]', ' ', claim)\n",
        "    # Removing some special characters\n",
        "    claim = re.sub(r'([\\;\\:\\|•«\\n])', ' ', claim)\n",
        "    # Removing stopwords except 'not' and 'can'\n",
        "    claim = \" \".join([word for word in claim.split()\n",
        "                  if word not in stopwords.words('english')\n",
        "                  or word in ['not', 'can']])\n",
        "    # Remove trailing whitespace\n",
        "    claim = re.sub(r'\\s+', ' ', claim).strip()\n",
        "    \n",
        "    return claim"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv8cKHitpGWY"
      },
      "source": [
        "### Tokenizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxcAqWPiltaX"
      },
      "source": [
        "In order to use a pre-trained BERT model, the input data needs to be converted into an appropriate format in order that each sentence can be sent to the pre-trained model to obtain the corresponding embedding. \n",
        "The tokenizer object allows the conversion from character strings to tokens understood by the different models.\n",
        "\n",
        "In order to tokenize any sentece, next steps need to be followed: \n",
        "\n",
        "*   **Step 1:** Add the [CLS] and [SEP] tokens: [CLS] token at the beginning, and the [SEP] token at the end of each input text.\n",
        "*   **Step 2:** Pad or truncate the sentence to the maximum length allowed: for sentences that are shorter than this maximum length, we will have to add paddings (empty tokens) to the sentences to make up the length.\n",
        "*   **Step 3**: Create the attention masks which explicitly differentiate real tokens from [PAD] tokens\n",
        "\n",
        "*Extracted from Huggingface transformers documentation: https://huggingface.co/transformers/model_doc/bert.html*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5rbCirGWXIg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "b8eb22f3770c4a0691b5f96fd6864432",
            "fc4eae3460334d97950433353c3f947b",
            "62a410cfdff64d8dadfa7b31d809c20b",
            "482759b81d474fd7931f835765687011",
            "2236d407e2ca49fe8ec56e24382781b3",
            "d36ae2477cd84bd1a159d00f726834c9",
            "c209f20c841c4208884df262a95fd6af",
            "af80454549b041c399ee269e0e57798f",
            "16e2caf4b56a489db91c64388ae2cde0",
            "d5ee6c3da25043a9bb6422cdad42a19f",
            "0a4d1a97593e4cce86597fdf4160ac98",
            "fa9c1271d2a84c3491400c91b617e589",
            "5aec79d192274f9489900474864ea30d",
            "fe6e4b6b5d4a4c5fb94d27c8bef022d6",
            "039905b077b74e1090741b4fc94c3f4f",
            "51f6e633f935406686d2bb5185e582f7",
            "7ce55d27d178471f9b40ae7e027209b0",
            "46487557663e45f5b7e2edf7c1223840",
            "5e6c94fac2404bbab6e1e23a444b78b9",
            "d1f8ba8587c74e96940afaa43ad9a29c",
            "0b204b4ca96d4dbc95fc4d06fde9e78f",
            "922737e171a74092a0cd870e602c8dda",
            "e6e2100761294054b23dda4600eb1a5b",
            "911f5efec12644d38732228c5df58e4f",
            "247db455a1374c9ca3543bb756855ac7",
            "956e5ab472bf43aa914f646668570f5a",
            "6b76e2cfca1f422d95ac5dff66f03315",
            "4bfc2ff8443c4545b9a91d606b9d128f",
            "0e1df319a9194304a53ab07e990b42b4",
            "94055c04e77a4bc5a519e6ac11f579f3",
            "5dcc6f2732384bda9ea28f0953398bfe",
            "31a4af39b566425794d5c75064c2cc2d",
            "232d565b81f040ffacef2519a7d7afda",
            "5754d21a0207482b93b3c99064638cc7",
            "16d1df343dc94e7089f945aeeed90115",
            "fc226e7be01e402f81aeb41be6baf421",
            "31f51d7e2734449ebb46e7c39285e518",
            "aa5ecfdb57db4948af59cc06a5e35e21",
            "242b1ab423e3430cbf8f8cc0bcbc49c5",
            "5a3e83d8973d474194d3cca1fe2530ab",
            "92974d6b3ea24cc5a7c4c096ad3790f1",
            "55de683f6ae34d369cb4cead6bf36997",
            "4ba28bb6ab7847429eac74344191830a",
            "ffd87f7ffb3c46b2b1f56aae8f1c0976"
          ]
        },
        "outputId": "bdda11fd-ec6b-4a90-e13e-6b05701c6eb9"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Loading the BERT tokenizer. Each model has its own tokenizer, and some tokenizing methods are different across tokenizers\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) \n",
        "\n",
        "# Creating a function to tokenize claims\n",
        "def preprocessing_claim_for_bert(data):\n",
        "    input_ids = []      # Empty lists to store outputs\n",
        "    attention_masks = []\n",
        "\n",
        "    for claim in data:\n",
        "        encoded_claim = tokenizer.encode_plus(  # Encode the tokens into their corresponding IDs \n",
        "            text = claim_preprocessing(claim),  # Step 0: Preprocessing claim\n",
        "            add_special_tokens=True,        # Step 1: Adding '[CLS]' and '[SEP]'\n",
        "            max_length = MAX_LEN,             # Max length to truncate/pad\n",
        "            pad_to_max_length = True,         # Step 2: Pad sentence to max length\n",
        "            return_attention_mask=True       # Step 3: Return attention mask\n",
        "            )\n",
        "        \n",
        "        # Adding the outputs to the lists\n",
        "        input_ids.append(encoded_claim.get('input_ids'))\n",
        "        attention_masks.append(encoded_claim.get('attention_mask'))\n",
        "\n",
        "    # Converting lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks # Returning inputs_ids and attention_masks as tensors"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8eb22f3770c4a0691b5f96fd6864432",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa9c1271d2a84c3491400c91b617e589",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6e2100761294054b23dda4600eb1a5b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5754d21a0207482b93b3c99064638cc7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RjbfNy8WW74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d3ecc8d-7dec-4205-bdeb-13eed5a3dd1b"
      },
      "source": [
        "# Concatenating claims \n",
        "all_claims = np.concatenate([df_dataset['claim'].values])\n",
        "\n",
        "# Encode our concatenated data\n",
        "encoded_claims = [tokenizer.encode(claim, add_special_tokens=True) for claim in all_claims]\n",
        "\n",
        "# Finding the maximum length\n",
        "max_len = max([len(claim) for claim in encoded_claims])\n",
        "print('Max length: ', max_len)\n",
        "\n",
        "#Specify 'MAX_LEN'\n",
        "MAX_LEN = max_len\n",
        "\n",
        "# Print sentence 0 and its encoded token ids\n",
        "token_ids = list(preprocessing_claim_for_bert([X[0]])[0].squeeze().numpy())\n",
        "print('Original: ', X[0])\n",
        "print('Token IDs: ', token_ids)\n",
        "\n",
        "# Run function 'preprocessing_claim_for_bert' on the train set and the validation set\n",
        "print('Tokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_claim_for_bert(X_train)\n",
        "val_inputs, val_masks = preprocessing_claim_for_bert(X_val)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length:  104\n",
            "Original:   A baby died at an unnamed medical facility because its parents refused to allow a black nurse to care for the child.\n",
            "Token IDs:  [101, 3336, 2351, 13294, 2966, 4322, 3008, 4188, 3499, 2304, 6821, 2729, 2775, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Tokenizing data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXBLfZ_IWW5H"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Converting other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "\n",
        "# In order to fine-tune BERT, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=8)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9KaXQay-mTf"
      },
      "source": [
        "## 5. Building and training the model - TL from BERT Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54pZZqFUuV0U"
      },
      "source": [
        "In order to complete the proposed task, we will use BERT to train a text classifier. Specifically, we will take the pre-trained BERT model, add an untrained layer of neurons on the end, and train the new model for our classification task. \n",
        "\n",
        "Fine-tunning this modeling has several advantages comparing it to training a specific deep learning model (a CNN, BiLSTM, etc.). Among others:\n",
        "- Less training time: the authors recommend only 2-4 epochs of training for fine-tuning BERT on a specific NLP task \n",
        "- Less data\n",
        "- Good results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2d2ju2Lw6Cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3998b2-d760-457e-d407-7dbb594121db"
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top\n",
        "# \"uncased\" because it has only lowercase letters and \"base\" because it is the smaller version of the two BERT pretrained models\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=5) \n",
        "model.cuda()\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407873900/407873900 [00:30<00:00, 13474362.61B/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKvbz-Df_SiS"
      },
      "source": [
        "As displayed before, we can see that each encoder layer has a BertEmbedding layer at the beginning, followed by a Transformer architecture (BertAttention, BertIntermediate, BertOutput). At the end of the 12 encoders, we have the Classifier layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftOJ-TUczR8X"
      },
      "source": [
        "Once we have loaded the pre-trained BERT model, we grab the training hyperparameters from within the stored model.\n",
        "\n",
        "For the purposes of fine-tuning, the authors recommend the following hyperparameter ranges:\n",
        "- Batch size: 16, 32\n",
        "- Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "- Number of epochs: 2, 3, 4\n",
        "\n",
        "References: https://developer.nvidia.com/blog/efficient-bert-finding-your-optimal-model-with-multimetric-bayesian-optimization-part-2/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6mtfvErw5-u"
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y77K5R2nw58-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f512078-71d8-4002-f5b8-dc089cf14bf1"
      },
      "source": [
        "# Optimizer variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                     lr=2e-5,\n",
        "                     warmup=.1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkLg8Smmw56s"
      },
      "source": [
        "# Calculating the accuracy of our predictions vs labels\n",
        "def get_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACwggXg_7LGa"
      },
      "source": [
        "Rarding the training of our model, we divide it in two phases:\n",
        "\n",
        "**Training loop:**\n",
        "\n",
        "- Setting the emodel in training mode (computing gradients)\n",
        "- Unpacking input data (inputs and labels)\n",
        "- Loading data into the GPU for acceleration\n",
        "- Clearing out the gradients calculated in the previous pass (in pytorch the gradients are accumulating by default)\n",
        "- Forward pass (feed input data through the network)\n",
        "- Backward pass (backpropagation)\n",
        "- Update parameters with optimizer.step()\n",
        "- Track variables for monitoring progress\n",
        "\n",
        "**Validation loop**:\n",
        "\n",
        "- Setting the emodel in evaluation mode (not computing gradients)\n",
        "- Unpacking input data (inputs and labels)\n",
        "- Loading data into the GPU for acceleration\n",
        "- Forward pass (feed input data through the network)\n",
        "- Computing loss on our validation data\n",
        "- Track variables for monitoring progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrPiIM1ww54G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46977571-c8dc-46b4-e0cb-48ab094c89fd"
      },
      "source": [
        "t = [] \n",
        "\n",
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training Loop\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "    train_loss_set.append(loss.item())    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "    \n",
        "  # Validation Loop\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in val_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = get_accuracy(logits, label_ids)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.0257126488851214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  25%|██▌       | 1/4 [08:12<24:36, 492.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.6023632271468145\n",
            "Train loss: 0.8968082181739702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  50%|█████     | 2/4 [16:22<16:21, 490.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.6336132271468145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SskYiVfczk21"
      },
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNgmVcve1ycl"
      },
      "source": [
        "## 6. Performance evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsBcKTwk1WLF"
      },
      "source": [
        "### Setup test dataset for BERT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GMxiz4-SHbr"
      },
      "source": [
        "# Running 'preprocessing_claim_for_bert' on the test set\n",
        "print('Tokenizing data...')\n",
        "test_inputs, test_masks = preprocessing_claim_for_bert(X_test)\n",
        "\n",
        "test_labels = torch.tensor(y_test)\n",
        "\n",
        "# Creating the DataLoader for our test set\n",
        "test_dataset = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mYj0suR2nKu"
      },
      "source": [
        "### Compute predicted probabilities on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZbiDbgSWWoJ"
      },
      "source": [
        "def seq_bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during the test time.\n",
        "    model.eval()\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "    \n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs # Output tensor with shape (batch_size, num_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TClxDKEWWfb"
      },
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = seq_bert_predict(model, test_dataloader)\n",
        "y_pred = np.argmax(probs, axis=1, out=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XBcKr0u91Ma"
      },
      "source": [
        "### Performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnFWA11MBvCO"
      },
      "source": [
        "def evaluate_classifier(y_pred, y_true):\n",
        "    preds = probs[:, 1]\n",
        "       \n",
        "    # Get accuracy over the test set\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
        "\n",
        "    # Plot a multilabel confusion matrix\n",
        "    fig = plt.figure()\n",
        "    skplt.metrics.plot_confusion_matrix(y_true, y_pred, figsize=(12,15))\n",
        "    fig.suptitle('Confusion Matrix', fontsize=16)\n",
        "\n",
        "    # Get Classification Report\n",
        "    print(pd.DataFrame(classification_report(y_true, y_pred, output_dict=True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGNask8GBvCP"
      },
      "source": [
        "# Evaluate the Bert classifier\n",
        "evaluate_classifier(y_pred, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YVAUVJnEBM5"
      },
      "source": [
        "#############"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFRHl-xvBgU7"
      },
      "source": [
        "When we use the trained model to predict the veracity on the unseen test dataset, the confusion matrix clearly shows how the model overfits to the majority True and False classes.\n",
        "\n",
        "Model performance can be increased with using additional techniques as Data Augmentation given that the input dataset is clearly bias including as the vast majority claims categorized as True and False."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA1ZRmMRmsGP"
      },
      "source": [
        "## Trying out the model with a new health claim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2V3fA-FnnKN"
      },
      "source": [
        "Once we have a final model, we apply it to a different health claim from a different source: \n",
        "\n",
        "**External claim:** *Receiving many vaccines for different diseases at the same time increases the risk of undesirable effects and can overload the immune system*\n",
        "\n",
        "**True label:** False\n",
        "\n",
        "Rationale found in http://proyectoavatar.enfermeriacomunitaria.org/vacunas/mitos-y-realidades (13rd Myth)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtwEygSmnsa-"
      },
      "source": [
        "external_claim = \"Receiving many vaccines for different diseases at the same time increases the risk of undesirable effects and can overload the immune system\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nuAdhslmzt8"
      },
      "source": [
        "# Running 'preprocessing_claim_for_bert' on the external claim\n",
        "print('Tokenizing data...')\n",
        "b_input_ids, b_attn_mask = preprocessing_claim_for_bert(external_claim)\n",
        "\n",
        "print('Applying BERT tokenizer prediction..')\n",
        "with torch.no_grad():\n",
        "    logits = model(b_input_ids.to(device), b_attn_mask.to(device))\n",
        "    probs = F.softmax(logits, dim=1).cpu().numpy()\n",
        "    y_pred = np.unique(np.argmax(probs, axis=1, out=None))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ7qHdgN1qyU"
      },
      "source": [
        "def veracity_prediction(y_pred):\n",
        "  if str(y_pred[0]) == '1':\n",
        "    return 'True'\n",
        "  if str(y_pred[0]) == '2':\n",
        "    return 'False'\n",
        "  if str(y_pred[0]) == '3':\n",
        "    return 'Mixture'\n",
        "  if str(y_pred[0]) == '4':\n",
        "    return 'Unproven'\n",
        "\n",
        "print('Veracity prediction: ' + veracity_prediction(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}